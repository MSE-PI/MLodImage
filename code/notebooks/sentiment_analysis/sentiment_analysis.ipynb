{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Topic detection and sentence generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test 1\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "# for test 2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# for sentence generation\n",
    "OPENAI_API_KEY = 'YOUR_KEY'\n",
    "import openai as ai\n",
    "\n",
    "# for test 4\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T11:12:24.888998Z",
     "end_time": "2023-04-04T11:12:25.027773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "texts = []\n",
    "text_bohemian_rhapsody = \"Is this the real life? Is this just fantasy? Caught in a landside, No escape from reality. Open your eyes, Look up to the skies and see. I'm just a poor boy, I need no sympathy. Because I'm easy come, easy go,Little high, little low. Any way the wind blows doesn't really matter to Me, to me. Mamaaa, Just killed a man, Put a gun against his head, pulled my trigger,Now he's dead. Mamaaa, life had just begun, But now I've gone and thrown it all away Mama, oooh. Didn't mean to make you cry. If I'm not back again this time tomorrow. Carry on, carry on as if nothing really matters\"\n",
    "\n",
    "text_happy = \"It might seem crazy what I am 'bout to say Sunshine, she's here, you can take a break. I'm a hot air balloon that could go to space With the air, like I don't care, baby by the way. Huh (Because I'm happy) Clap along if you feel like a room without a roof. (Because I'm happy) Clap along if you feel like happiness is the truth. (Because I'm happy) Clap along if you know what happiness is to you. (Because I'm happy) Clap along if you feel like that's what you wanna do\"\n",
    "\n",
    "text_heathens = \"All my friends are heathens, take it slow. Wait for them to ask you who you know. Please don't make any sudden moves. You don't know the half of the abuse. Welcome to the room of people. Who have rooms of people that they loved one day. Docked away. Just because we check the guns at the door. Doesn't mean our brains will change from hand grenades. You'll never know the psychopath sitting next to you. You'll never know the murderer sitting next to you. You'll think, \\\"How'd I get here, sitting next to you?\\\". But after all I've said, please don't forget\"\n",
    "\n",
    "text_iron_maiden = \" Do I am a man who walks alone and when I'm walking a dark road At night I'm strolling through the park When the light begins to change, sometimes you're a little strange A little anxious when it's dark Fear of the dark, fear of the dark I have a constant fear that something's always near Fear of the dark, fear of the dark I have a phobia that someone's always there Have you run your fingers down the wall? And have you been your next game ball? When the sun came for light? Sometimes when you're scared to take a look At the corner of the room, you're sex and stuff Fear of the dark, fear of the dark I have a constant fear that something's always near Fear of the dark, fear of the dark I have a phobia that someone's always there Have you ever been alone at night? Thought you were possessed behind I turned around and knew what's there And as you quicken up your back, you're fighting hard to look again Because you're sure that someone there Fear of the dark, fear of the dark I have a constant fear that something's always near Fear of the dark, fear of the dark I have a phobia that someone's always there Fear of the dark I have a phobia that someone's always there Fear of the dark, fear of the dark I have a phobia that someone's always there Fear of the dark I have a phobia that someone's always there Fear of the dark I have a phobia that someone's always there Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark Watching our abelves the night before Debrating witches and moths law The unknown troubles on your mind Maybe your mind is plain Trace who sends a sudden reaction A dancing shadow from behind Fear of the dark Fear of the dark I have a hunch that fear of somethings always fear Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark I have a hunch that fear of somethings always fear Fear of the dark Fear of the dark Fear of the dark Fear of the dark Fear of the dark When I'm walking the dark road I am a man who walks alone I am a man who walks alone\"\n",
    "\n",
    "texts.append(text_bohemian_rhapsody)\n",
    "texts.append(text_happy)\n",
    "texts.append(text_heathens)\n",
    "texts.append(text_iron_maiden)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T20:08:10.245813Z",
     "end_time": "2023-04-03T20:08:10.249044Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 1\n",
    "source: https://github.com/pysentimiento/pysentimiento"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x7f60d7be8df0>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.factory(\"custom_language_detector\")\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"custom_language_detector\", name=\"language_detector\", last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T19:59:46.886688Z",
     "end_time": "2023-04-03T19:59:47.653827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "emotion_analyzer = create_analyzer(task='emotion', lang='en')\n",
    "\n",
    "def get_metadata(input):\n",
    "    doc = nlp(input)\n",
    "    # document level language detection. Think of it like average language of document!\n",
    "    print(f\"detected global lang: {doc._.language}\")\n",
    "    print(f\"detected global emotion: {emotion_analyzer.predict(input)}\")\n",
    "    # sentence level language detection\n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        print(f\"detected lang: {sent} - {sent._.language}\")\n",
    "        print(f\"detected emotion: {emotion_analyzer.predict(sent.text)}\")\n",
    "\n",
    "    return doc._.language, emotion_analyzer.predict(input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T19:59:48.925739Z",
     "end_time": "2023-04-03T19:59:52.071007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected global lang: {'language': 'en', 'score': 0.9999975300350009}\n",
      "detected global emotion: AnalyzerOutput(output=others, probas={others: 0.741, disgust: 0.189, sadness: 0.050, joy: 0.006, fear: 0.005, anger: 0.005, surprise: 0.003})\n",
      "detected lang: Is this the real life? - {'language': 'en', 'score': 0.9999977022642051}\n",
      "detected emotion: AnalyzerOutput(output=surprise, probas={surprise: 0.949, others: 0.029, fear: 0.007, sadness: 0.005, joy: 0.005, anger: 0.003, disgust: 0.002})\n",
      "detected lang: Is this just fantasy? - {'language': 'en', 'score': 0.9999973004575105}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.967, disgust: 0.010, surprise: 0.009, joy: 0.007, fear: 0.004, anger: 0.002, sadness: 0.002})\n",
      "detected lang: Caught in a landside, No escape from reality. - {'language': 'en', 'score': 0.9999969590340752}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.968, disgust: 0.011, joy: 0.008, sadness: 0.005, fear: 0.003, surprise: 0.003, anger: 0.002})\n",
      "detected lang: Open your eyes, Look up to the skies and see. - {'language': 'en', 'score': 0.7142840830128286}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.970, joy: 0.015, fear: 0.004, sadness: 0.004, disgust: 0.003, surprise: 0.003, anger: 0.001})\n",
      "detected lang: I'm just a poor boy, I need no sympathy. - {'language': 'en', 'score': 0.9999952138523633}\n",
      "detected emotion: AnalyzerOutput(output=sadness, probas={sadness: 0.988, fear: 0.003, others: 0.003, disgust: 0.003, anger: 0.001, joy: 0.001, surprise: 0.001})\n",
      "detected lang: Because I'm easy come, easy go,Little high, little low. - {'language': 'en', 'score': 0.9999968970252562}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.973, joy: 0.015, disgust: 0.004, surprise: 0.003, anger: 0.002, fear: 0.002, sadness: 0.001})\n",
      "detected lang: Any way the wind blows doesn't really matter to Me, to me. - {'language': 'en', 'score': 0.9999982838110191}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.960, joy: 0.020, fear: 0.007, sadness: 0.005, disgust: 0.004, surprise: 0.003, anger: 0.001})\n",
      "detected lang: Mamaaa, Just killed a man, Put a gun against his head, pulled my trigger,Now he's dead. - {'language': 'en', 'score': 0.8571402272465014}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.954, fear: 0.017, joy: 0.009, sadness: 0.007, disgust: 0.006, anger: 0.004, surprise: 0.002})\n",
      "detected lang: Mamaaa, life had just begun, But now I've gone and thrown it all away Mama, oooh. - {'language': 'en', 'score': 0.999996912281089}\n",
      "detected emotion: AnalyzerOutput(output=sadness, probas={sadness: 0.980, others: 0.010, disgust: 0.003, surprise: 0.002, fear: 0.002, joy: 0.002, anger: 0.001})\n",
      "detected lang: Didn't mean to make you cry. - {'language': 'en', 'score': 0.9999968216605714}\n",
      "detected emotion: AnalyzerOutput(output=sadness, probas={sadness: 0.947, others: 0.036, disgust: 0.004, joy: 0.004, fear: 0.004, surprise: 0.003, anger: 0.002})\n",
      "detected lang: If I'm not back again this time tomorrow. - {'language': 'en', 'score': 0.9999974517180185}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.505, sadness: 0.353, fear: 0.095, joy: 0.031, disgust: 0.007, surprise: 0.006, anger: 0.004})\n",
      "detected lang: Carry on, carry on as if nothing really matters - {'language': 'en', 'score': 0.9999950629690659}\n",
      "detected emotion: AnalyzerOutput(output=others, probas={others: 0.946, joy: 0.025, fear: 0.009, sadness: 0.009, surprise: 0.006, disgust: 0.004, anger: 0.001})\n"
     ]
    }
   ],
   "source": [
    "global_language, global_sentiments = get_metadata(texts[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T19:59:54.935179Z",
     "end_time": "2023-04-03T19:59:55.722811Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 2\n",
    "source: https://www.toptal.com/python/topic-modeling-python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', lowercase=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T20:00:03.115297Z",
     "end_time": "2023-04-03T20:00:03.121238Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['just', 'carry', 'mamaaa', 'really', 'life', 'easy', 'little', 'matter', 'eyes', 'escape']\n",
      "\n",
      "Topic 1:\n",
      "['just', 'little', 'easy', 'life', 'really', 'mamaaa', 'carry', 'doesn', 'need', 'way']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_counts = count_vect.fit_transform([texts[0]])\n",
    "x_counts.todense()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_tfidf = tfidf_transformer.fit_transform(x_counts)\n",
    "\n",
    "dimension = 2\n",
    "lda = LDA(n_components = dimension)\n",
    "lda_array = lda.fit_transform(x_tfidf)\n",
    "\n",
    "components = [lda.components_[i] for i in range(len(lda.components_))]\n",
    "features = count_vect.get_feature_names_out()\n",
    "\n",
    "# classify the most important words in each topic\n",
    "topic_arrays = []\n",
    "for i, component in enumerate(components):\n",
    "    print(f\"Topic {i}:\")\n",
    "    topic_array = [features[j] for j in component.argsort()[:-10 - 1:-1]]\n",
    "    print(topic_array)\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T20:00:04.066809Z",
     "end_time": "2023-04-03T20:00:04.094111Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence generation\n",
    "source: https://accessibleai.dev/post/generating_text_with_gpt_and_python/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def generate_gpt3_response(user_text, print_output=False):\n",
    "    \"\"\"\n",
    "    Query OpenAI GPT-3 for the specific key and get back a response\n",
    "    :type user_text: str the user's text to query for\n",
    "    :type print_output: boolean whether to print the raw output JSON\n",
    "    \"\"\"\n",
    "    completions = ai.Completion.create(\n",
    "        engine='text-davinci-003',  # Determines the quality, speed, and cost.\n",
    "        temperature=0.5,            # Level of creativity in the response\n",
    "        prompt=user_text,           # What the user typed in\n",
    "        max_tokens=100,             # Maximum tokens in the prompt AND response\n",
    "        n=1,                        # The number of completions to generate\n",
    "        stop=None,                  # An optional setting to control response generation\n",
    "    )\n",
    "\n",
    "    # Displaying the output can be helpful if things go wrong\n",
    "    if print_output:\n",
    "        print(completions)\n",
    "\n",
    "    # Return the first choice's text\n",
    "    return completions.choices[0].text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Don't know the way I feel the happiness in the air, but I'm happy to clap like it's a room full of joy.\n",
      "\n",
      "\n",
      "I feel so happy and free, clapping with joy in the air, as if the truth of happiness was breaking through the space around me.\n",
      "\n",
      "\n",
      "\"I just know that the little people sitting here don't really carry mamaaa, but I'm sure they have something special to offer.\"\n"
     ]
    }
   ],
   "source": [
    "for topic in topic_arrays:\n",
    "    prompt = 'Generate a descriptive sentence that can be given to an image generation service using the following keywords: ' + ', '.join(topic)\n",
    "    response = generate_gpt3_response(prompt)\n",
    "    print(response)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "A poor boy faces a difficult reality, but still carries on with determination despite the hardships.\n",
      ".\n",
      "\n",
      "A person feeling joyous and carefree, clapping and singing along to a happy song.\n",
      ".\n",
      "\n",
      "A group of people, some with hidden secrets, come together in an unfamiliar place, with a warning to take it slow and not make any sudden moves.\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    prompt = 'Describe me these song lyrics in one sentence that can be given to an image generation service: ' + text\n",
    "    response = generate_gpt3_response(prompt)\n",
    "    print(response)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_gpt3_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m lyrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMay I have your attention please? I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm not afraid (I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm not afraid) To skinny dip (to skinny dip) Everybody (everybody) Come take my leg (come take my leg) We\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mll walk through Canada together, through the storm Whatever weather, cold or warm His toes are stinky, insides clammy, fingers are skinny There\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms food on his dungarees already, doctor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms soup He\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms nervous, but on the surface he looks calm and ready to skinny dip, But he keeps on forgetting what he wrote down, And I am, a dreamer If I wasn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt, then why would I say I am? In the paper, the news everyday I am Radio won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt even play my jam Cause I am, a dreamer If I wasn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt, then why would I say I am? In the paper, the news everyday I am I don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know it\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms just the way I am You better skinny dip You own it, you better never let it go You only get one shot, do not miss your chance to skinny dip This opportunity comes once in a lifetime yo You better skinny dip You own it, you better never let it go You only get one shot, do not miss your chance to skinny dip This opportunity comes once in a lifetime yo So lets go back Follow the old lady as we go on another episode Journey with me as I take you through Canada I once used to call home sweet home Well, gotta go, I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm almost at the school now And when I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm gone, just skinny dip, don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt mourn Rejoice every time you hear the sound of my stinky toes Just know that I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm looking down on you running And I didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt feel a thing, So baby don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt feel no pain Just skinny dip And when he\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms gone, just skinny dip, don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt mourn Rejoice every time you hear the sound of his clammy insides Just know that he\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms looking down on you smooching And his didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt feel a thing, So baby don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt feel no pain Just skinny dip in your dungarees.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mImagine a song title for these lyrics: \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m lyrics\n\u001B[0;32m----> 3\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_gpt3_response\u001B[49m(prompt)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generate_gpt3_response' is not defined"
     ]
    }
   ],
   "source": [
    "lyrics = \"May I have your attention please? I'm not afraid (I'm not afraid) To skinny dip (to skinny dip) Everybody (everybody) Come take my leg (come take my leg) We'll walk through Canada together, through the storm Whatever weather, cold or warm His toes are stinky, insides clammy, fingers are skinny There's food on his dungarees already, doctor's soup He's nervous, but on the surface he looks calm and ready to skinny dip, But he keeps on forgetting what he wrote down, And I am, a dreamer If I wasn't, then why would I say I am? In the paper, the news everyday I am Radio won't even play my jam Cause I am, a dreamer If I wasn't, then why would I say I am? In the paper, the news everyday I am I don't know it's just the way I am You better skinny dip You own it, you better never let it go You only get one shot, do not miss your chance to skinny dip This opportunity comes once in a lifetime yo You better skinny dip You own it, you better never let it go You only get one shot, do not miss your chance to skinny dip This opportunity comes once in a lifetime yo So lets go back Follow the old lady as we go on another episode Journey with me as I take you through Canada I once used to call home sweet home Well, gotta go, I'm almost at the school now And when I'm gone, just skinny dip, don't mourn Rejoice every time you hear the sound of my stinky toes Just know that I'm looking down on you running And I didn't feel a thing, So baby don't feel no pain Just skinny dip And when he's gone, just skinny dip, don't mourn Rejoice every time you hear the sound of his clammy insides Just know that he's looking down on you smooching And his didn't feel a thing, So baby don't feel no pain Just skinny dip in your dungarees.\"\n",
    "prompt = 'Imagine a song title for these lyrics: ' + lyrics\n",
    "response = generate_gpt3_response(prompt)\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real', 'caught', 'no', 'escape', 'open', 'look', 'skies', 'poor', 'need', 'because']\n"
     ]
    }
   ],
   "source": [
    "# get total words in text\n",
    "total_words = texts[0].split()\n",
    "\n",
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "total_words = [w for w in total_words if not w in stop_words]\n",
    "\n",
    "# remove punctuation\n",
    "total_words = [w for w in total_words if w.isalpha()]\n",
    "\n",
    "# count total words in lyrics\n",
    "total_words_len = len(total_words)\n",
    "\n",
    "# count total sentences in lyrics\n",
    "total_sentences = tokenize.sent_tokenize(texts[0])\n",
    "total_sent_len = len(total_sentences)\n",
    "\n",
    "# calculate tf for each word\n",
    "tf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in tf_score:\n",
    "            tf_score[each_word] += 1\n",
    "        else:\n",
    "            tf_score[each_word] = 1\n",
    "\n",
    "# Dividing by total_word_length for each dictionary element\n",
    "tf_score.update((x, y/int(total_words_len)) for x, y in tf_score.items())\n",
    "\n",
    "def check_sent(word, sentences):\n",
    "    final = [all([w in x for w in word]) for x in sentences]\n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))\n",
    "\n",
    "idf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in idf_score:\n",
    "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "        else:\n",
    "            idf_score[each_word] = 1\n",
    "\n",
    "# Performing a log and divide\n",
    "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "\n",
    "def filter_insignificant(chunk, tag_suffixes=['DT', 'CC', 'PRP']):\n",
    "    good = []\n",
    "    for word, tag in chunk:\n",
    "        ok = True\n",
    "        for suffix in tag_suffixes:\n",
    "            if tag.endswith(suffix):\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            good.append((word, tag))\n",
    "    return good\n",
    "\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True))\n",
    "    # for each word get nltk tag\n",
    "    result = nltk.pos_tag(result)\n",
    "    result = filter_insignificant(result)\n",
    "    result = [word.lower() for word, tag in result]\n",
    "    return result[:n]\n",
    "\n",
    "print(get_top_n(tf_idf_score, 10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T20:09:25.595097Z",
     "end_time": "2023-04-03T20:09:25.615726Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'sentiments': {'others': 0.7412168383598328, 'joy': 0.006226531229913235, 'sadness': 0.05005769059062004, 'anger': 0.005120564252138138, 'surprise': 0.0028682444244623184, 'disgust': 0.18911521136760712, 'fear': 0.005394992418587208}, 'top_words': ['real', 'caught', 'no', 'escape', 'open', 'look', 'skies', 'poor', 'need', 'because']}\n"
     ]
    }
   ],
   "source": [
    "# Create json with infos (global language, global sentiments, top n words)\n",
    "json_result = {\n",
    "    \"language\": global_language[\"language\"],\n",
    "    \"sentiments\": global_sentiments.probas,\n",
    "    \"top_words\": get_top_n(tf_idf_score, 10)\n",
    "}\n",
    "print(json_result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T20:09:40.193236Z",
     "end_time": "2023-04-03T20:09:40.195474Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
